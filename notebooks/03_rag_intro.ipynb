{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd58d40c",
   "metadata": {},
   "source": [
    "# ðŸ“š Intro to Retrieval-Augmented Generation (RAG)\n",
    "RAG pipelines with FAISS, Chroma, and Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a910974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS, Chroma, Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import pinecone, os\n",
    "\n",
    "loader = TextLoader(\"docs/sample.txt\")\n",
    "docs = loader.load()\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# Embedding setup\n",
    "openai_embed = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "hf_embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# FAISS\n",
    "faiss_store = FAISS.from_documents(chunks, openai_embed)\n",
    "\n",
    "# Chroma\n",
    "chroma_store = Chroma.from_documents(chunks, hf_embed, collection_name=\"genai_demo\")\n",
    "\n",
    "# Pinecone\n",
    "pinecone.init(api_key=os.getenv(\"VECTOR_DB_API_KEY\"), environment=\"us-west1-gcp\")\n",
    "pc_store = Pinecone.from_documents(chunks, openai_embed, index_name=os.getenv(\"VECTOR_DB_INDEX\"))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
